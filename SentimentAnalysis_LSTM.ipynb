{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVo8oJVNRh76XLYlnEtAop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AishwaryaPonni/Madrix_text_analysis/blob/main/SentimentAnalysis_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6unAwMldmZg",
        "outputId": "3247a2ca-023a-4b21-985c-8075d5c2f7f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzUNd4GXdt6p"
      },
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "W_13fnHvhfFS",
        "outputId": "369f9455-3358-41a8-8a36-189cbf72e97a"
      },
      "source": [
        "train = pd.read_csv('/content/gdrive/MyDrive/IETE text analysis /imdb dataset/cleaned dataset.csv')\n",
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>one reviewer mentioned watching 1 oz episode y...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>wonderful little production filming technique ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>basically there family little boy jake think t...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>petter matteis love time money visually stunni...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                             review sentiment\n",
              "0           0  one reviewer mentioned watching 1 oz episode y...  positive\n",
              "1           1  wonderful little production filming technique ...  positive\n",
              "2           2  thought wonderful way spend time hot summer we...  positive\n",
              "3           3  basically there family little boy jake think t...  negative\n",
              "4           4  petter matteis love time money visually stunni...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owlhrACSkQJA",
        "outputId": "22e68d3c-6e90-45c7-b2fc-edb3c1635b2b"
      },
      "source": [
        "train['sentiment'].unique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive', 'negative'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWQQa9lkkhCs"
      },
      "source": [
        "#removing html\n",
        "from bs4 import BeautifulSoup\n",
        "def strip_html(text):\n",
        "  soup = BeautifulSoup(text, 'html.parser')\n",
        "  return soup.get_text()\n",
        "\n",
        "#removing square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "#removing special characters\n",
        "def remove_special_characters(text):\n",
        "  pattern = r'[^a-zA-z0-9\\s]'\n",
        "  text = re.sub(pattern,'',text)\n",
        "  return text\n",
        "\n",
        "#combining into one function\n",
        "def denoise_text(text):\n",
        "  text = strip_html(text)\n",
        "  text = remove_between_square_brackets(text)\n",
        "  text = remove_special_characters(text)\n",
        "  text = text.lower() #converting all letters to lowercase\n",
        "  return text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3fpp9rEkrnt",
        "outputId": "93753d2c-6a4b-43c8-9622-ddcab08557e8"
      },
      "source": [
        "max_len = max(len(review) for review in train['review'])\n",
        "print(max_len)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRX8aKvDm3xq"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ9BidtwnXkz",
        "outputId": "8b302eba-5207-4b02-eff3-560802a8d153"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S5qPnyuo3sF",
        "outputId": "0bceb6a0-219a-4839-950b-7dc6198d52f6"
      },
      "source": [
        "train['sentiment'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    25000\n",
              "positive    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPYqcKcml2CP",
        "outputId": "5ee6a54c-b6f5-4aa3-c6b4-99f817a65e9f"
      },
      "source": [
        "max_words = 5000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(train['review'])\n",
        "sequences = tokenizer.texts_to_sequences(train['review'])\n",
        "trainData = pad_sequences(sequences, maxlen=max_len)\n",
        "print(trainData)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...  784 3679  350]\n",
            " [   0    0    0 ... 1754   17  132]\n",
            " [   0    0    0 ...   31   13  112]\n",
            " ...\n",
            " [   0    0    0 ...  264  388 3594]\n",
            " [   0    0    0 ... 1844 2350  603]\n",
            " [   0    0    0 ...  898  727    1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuLAxBW2obwH",
        "outputId": "ae254df0-6194-45f0-ed64-2cfb487a2867"
      },
      "source": [
        "labels = np.array(train['sentiment'])\n",
        "y = []\n",
        "for i in range(len(labels)):\n",
        "    if labels[i] == 'negative':\n",
        "        y.append(0)\n",
        "    if labels[i] == 'positive':\n",
        "        y.append(1)\n",
        "y = np.array(y)\n",
        "labels = tf.keras.utils.to_categorical(y, 2, dtype=\"float32\")\n",
        "del y\n",
        "print(labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnpuY65HoRZ8",
        "outputId": "79784690-4158-40a2-a73a-1c8267331010"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(trainData,labels, random_state=0)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37500 12500 37500 12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_l1Dp9LpCpS",
        "outputId": "8ad85c29-06bf-43a0-d398-ea2a0f218344"
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(layers.Embedding(max_words, 20))\n",
        "model1.add(layers.LSTM(15,dropout=0.5))\n",
        "model1.add(layers.Dense(2,activation='sigmoid'))\n",
        "model1.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 20)          100000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 15)                2160      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 32        \n",
            "=================================================================\n",
            "Total params: 102,192\n",
            "Trainable params: 102,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn4esEfJs5V6",
        "outputId": "9031d69c-ab0a-4399-b0d0-20e926f2f471"
      },
      "source": [
        "print(y_train)\n",
        "y_train.shape\n",
        "y_test.shape\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMEj_c4Gqyuv",
        "outputId": "1a4a4e5c-176b-4cd2-f642-5a54a3a9e040"
      },
      "source": [
        "model1.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
        "# checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model1.fit(X_train, y_train, epochs=20,validation_data=(X_test, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1172/1172 [==============================] - 324s 248ms/step - loss: 0.4946 - accuracy: 0.7548 - val_loss: 0.2899 - val_accuracy: 0.8777\n",
            "Epoch 2/20\n",
            "1172/1172 [==============================] - 289s 247ms/step - loss: 0.2660 - accuracy: 0.8941 - val_loss: 0.2805 - val_accuracy: 0.8878\n",
            "Epoch 3/20\n",
            "1172/1172 [==============================] - 284s 242ms/step - loss: 0.2443 - accuracy: 0.9036 - val_loss: 0.2648 - val_accuracy: 0.8930\n",
            "Epoch 4/20\n",
            "1172/1172 [==============================] - 284s 242ms/step - loss: 0.2437 - accuracy: 0.9021 - val_loss: 0.2983 - val_accuracy: 0.8861\n",
            "Epoch 5/20\n",
            "1172/1172 [==============================] - 284s 243ms/step - loss: 0.2384 - accuracy: 0.9057 - val_loss: 0.2903 - val_accuracy: 0.8905\n",
            "Epoch 6/20\n",
            "1172/1172 [==============================] - 283s 242ms/step - loss: 0.2328 - accuracy: 0.9071 - val_loss: 0.2691 - val_accuracy: 0.8894\n",
            "Epoch 7/20\n",
            "1172/1172 [==============================] - 282s 241ms/step - loss: 0.2272 - accuracy: 0.9098 - val_loss: 0.2732 - val_accuracy: 0.8899\n",
            "Epoch 8/20\n",
            "1172/1172 [==============================] - 282s 240ms/step - loss: 0.2220 - accuracy: 0.9120 - val_loss: 0.2656 - val_accuracy: 0.8898\n",
            "Epoch 9/20\n",
            "1172/1172 [==============================] - 285s 243ms/step - loss: 0.2214 - accuracy: 0.9135 - val_loss: 0.2656 - val_accuracy: 0.8896\n",
            "Epoch 10/20\n",
            "1172/1172 [==============================] - 286s 244ms/step - loss: 0.2193 - accuracy: 0.9139 - val_loss: 0.2654 - val_accuracy: 0.8924\n",
            "Epoch 11/20\n",
            "1172/1172 [==============================] - 285s 243ms/step - loss: 0.2179 - accuracy: 0.9162 - val_loss: 0.2804 - val_accuracy: 0.8913\n",
            "Epoch 12/20\n",
            "1172/1172 [==============================] - 283s 242ms/step - loss: 0.2132 - accuracy: 0.9168 - val_loss: 0.2814 - val_accuracy: 0.8924\n",
            "Epoch 13/20\n",
            "1172/1172 [==============================] - 286s 244ms/step - loss: 0.2193 - accuracy: 0.9137 - val_loss: 0.2633 - val_accuracy: 0.8930\n",
            "Epoch 14/20\n",
            "1172/1172 [==============================] - 288s 246ms/step - loss: 0.2142 - accuracy: 0.9188 - val_loss: 0.2670 - val_accuracy: 0.8934\n",
            "Epoch 15/20\n",
            "1172/1172 [==============================] - 286s 244ms/step - loss: 0.2109 - accuracy: 0.9198 - val_loss: 0.2676 - val_accuracy: 0.8897\n",
            "Epoch 16/20\n",
            "1172/1172 [==============================] - 285s 243ms/step - loss: 0.2071 - accuracy: 0.9189 - val_loss: 0.2838 - val_accuracy: 0.8910\n",
            "Epoch 17/20\n",
            "1172/1172 [==============================] - 282s 241ms/step - loss: 0.2054 - accuracy: 0.9218 - val_loss: 0.2743 - val_accuracy: 0.8872\n",
            "Epoch 18/20\n",
            "1172/1172 [==============================] - 281s 240ms/step - loss: 0.2051 - accuracy: 0.9197 - val_loss: 0.2756 - val_accuracy: 0.8874\n",
            "Epoch 19/20\n",
            "1172/1172 [==============================] - 281s 240ms/step - loss: 0.2016 - accuracy: 0.9220 - val_loss: 0.3409 - val_accuracy: 0.8689\n",
            "Epoch 20/20\n",
            "1172/1172 [==============================] - 281s 240ms/step - loss: 0.2028 - accuracy: 0.9203 - val_loss: 0.2603 - val_accuracy: 0.8944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z1dmQrYH-Es",
        "outputId": "7cb4469b-b88d-4113-9440-d8f9e44589b6"
      },
      "source": [
        "test_loss, test_acc = model1.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 - 39s - loss: 0.2603 - accuracy: 0.8944\n",
            "Model accuracy:  0.8944000005722046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Our-41uItnZ",
        "outputId": "fc78d780-542f-4d53-a3dc-8a6faf0dfa52"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model2.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
        "model2.add(layers.Dense(2,activation='sigmoid'))\n",
        "model2.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
        "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model2.fit(X_train, y_train, epochs=20,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/20\n",
            "1172/1172 [==============================] - 577s 490ms/step - loss: 0.4865 - accuracy: 0.7578 - val_loss: 0.2815 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.88560, saving model to best_model2.hdf5\n",
            "Epoch 2/20\n",
            "1172/1172 [==============================] - 575s 491ms/step - loss: 0.2705 - accuracy: 0.8909 - val_loss: 0.2701 - val_accuracy: 0.8921\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.88560 to 0.89208, saving model to best_model2.hdf5\n",
            "Epoch 3/20\n",
            "1172/1172 [==============================] - 575s 491ms/step - loss: 0.2465 - accuracy: 0.9000 - val_loss: 0.2866 - val_accuracy: 0.8823\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.89208\n",
            "Epoch 4/20\n",
            "1172/1172 [==============================] - 573s 489ms/step - loss: 0.2435 - accuracy: 0.9040 - val_loss: 0.2624 - val_accuracy: 0.8931\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89208 to 0.89312, saving model to best_model2.hdf5\n",
            "Epoch 5/20\n",
            "1172/1172 [==============================] - 572s 488ms/step - loss: 0.2269 - accuracy: 0.9115 - val_loss: 0.2802 - val_accuracy: 0.8915\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.89312\n",
            "Epoch 6/20\n",
            "1172/1172 [==============================] - 573s 489ms/step - loss: 0.2214 - accuracy: 0.9121 - val_loss: 0.2646 - val_accuracy: 0.8918\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.89312\n",
            "Epoch 7/20\n",
            "1172/1172 [==============================] - 577s 492ms/step - loss: 0.2207 - accuracy: 0.9138 - val_loss: 0.2701 - val_accuracy: 0.8930\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.89312\n",
            "Epoch 8/20\n",
            "1172/1172 [==============================] - 572s 488ms/step - loss: 0.2206 - accuracy: 0.9151 - val_loss: 0.2631 - val_accuracy: 0.8938\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.89312 to 0.89376, saving model to best_model2.hdf5\n",
            "Epoch 9/20\n",
            "1172/1172 [==============================] - 572s 489ms/step - loss: 0.2204 - accuracy: 0.9130 - val_loss: 0.2791 - val_accuracy: 0.8822\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.89376\n",
            "Epoch 10/20\n",
            "1172/1172 [==============================] - 574s 490ms/step - loss: 0.2171 - accuracy: 0.9146 - val_loss: 0.2810 - val_accuracy: 0.8894\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.89376\n",
            "Epoch 11/20\n",
            "1172/1172 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.9207"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}